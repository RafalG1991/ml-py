{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e70e366-95c8-4cc8-8382-70784db011c9",
   "metadata": {},
   "source": [
    "LAB 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf00521-44cf-4a84-8499-17b0a322c095",
   "metadata": {},
   "source": [
    "Task 1.\n",
    "Import necessary libraries: from tensorflow import keras and ` from tensorflow.keras import layers.\n",
    "\n",
    "Loadtrain_images, train_labels, test_images, test_labelsfrom data setmnistfromtensorflow.keras.datasets. What are the shape and type of train_imagesandtest_images`?\n",
    "\n",
    "Preprocess the data by reshaping it into the shape the model expects and scaling it so that all values are in the [0, 1] interval: Change tensors train_images and test_images into rank-2 tensors of shape \n",
    ", \n",
    ", respectively. Change type of these tensors into float32 and standardize them: divide them by the their maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3296c9-1f8d-428e-87c9-d7603e3d13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d09cf9-ba4c-4d5d-aca7-8d808069d13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 5us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b38de7d-5a6f-42b8-ac75-b58cfe597155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Shape: (60000, 28, 28) Type: uint8\n",
      "Test Images Shape: (10000, 28, 28) Type: uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Images Shape:\", train_images.shape, \"Type:\", train_images.dtype)\n",
    "print(\"Test Images Shape:\", test_images.shape, \"Type:\", test_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b8dce05-cd0b-4d8a-8de9-337bce19c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped Train Images Shape: (60000, 784) Type: float32\n",
      "Reshaped Test Images Shape: (10000, 784) Type: float32\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images.reshape(60000, 28*28).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape(10000, 28*28).astype(\"float32\") / 255\n",
    "\n",
    "print(\"Reshaped Train Images Shape:\", train_images.shape, \"Type:\", train_images.dtype)\n",
    "print(\"Reshaped Test Images Shape:\", test_images.shape, \"Type:\", test_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41759f-cdb7-448a-b061-7bc049ca3031",
   "metadata": {},
   "source": [
    "Taks 2\n",
    "Using function Sequential from Keras create a model consisting of a sequence of two densely connected neural layers. The first layer should consists of 512 parameters and its activation function should be reLU. The second (and last) layer is to be a 10-way softmax classification layer, which means it will return an array of 10 probability scores (summing to 1). Each score will be the probability that the current digit image belongs to one of 10 digit classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5924ac7-401b-4b35-ae3f-3571634fa42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,050</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m407,050\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)), \n",
    "    layers.Dense(10, activation=\"softmax\") \n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9c596-467a-4974-b6d3-74ae689ecf14",
   "metadata": {},
   "source": [
    "Task 3\n",
    "Compile the model using rmsprop algorithm as an optimizer, sparse_categorical_crossentropy as a loss function, and the accuracy (the fraction of the images that were correctly classified) as a metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead04f28-6fde-48ec-af8c-5914281ebd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", \n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9aac3-a2e8-414a-903f-fffe74603888",
   "metadata": {},
   "source": [
    "Task 4\n",
    "Fit the model to its training data using 5 epochs and batch_size=128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e33744-66b9-4995-bb29-fb3a3f959547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.4380\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1193\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0715\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0504\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0367\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526dc97c-10e6-4af3-82af-e26db71f4868",
   "metadata": {},
   "source": [
    "Task 5\n",
    "Use the trained model to predict class probabilities for digits from test_images and for each digit compare the index with the greatest probability with apropriate element in test_labels. Find the first digit from test_images for which label predicted by the model is different from the true label form test_labels. What is the true digit and its prediction? Plot this digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a0c4b0-b263-4fd9-947f-f8fd7bc3076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a110800-6d8c-4de8-bc2d-da7d5e7f88ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First misclassified digit index: 33\n",
      "True Label: 4, Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if predicted_labels[i] != test_labels[i]:\n",
    "        first_misclassified_index = i\n",
    "        break\n",
    "\n",
    "true_label = test_labels[first_misclassified_index]\n",
    "predicted_label = predicted_labels[first_misclassified_index]\n",
    "\n",
    "print(f\"First misclassified digit index: {first_misclassified_index}\")\n",
    "print(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d643f4a-6d9f-4115-aaba-2a437c224a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[first_misclassified_index].reshape(28, 28), cmap=plt.cm.binary)\n",
    "plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a36685-cf7c-431c-ab37-fba890cf792a",
   "metadata": {},
   "source": [
    "Task 6\n",
    "Evaluate the model on training and test data. Compare the test-set accuracy/loss with the training-set accuracy/loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b268fdd2-7b67-497f-b865-e0da8990753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0258, Training Accuracy: 0.9933\n",
      "Test Loss: 0.0620, Test Accuracy: 0.9801\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc7b34-b016-442a-9d44-4581dab3ff6a",
   "metadata": {},
   "source": [
    "Task 7\n",
    "Do tasks 4 and 6 using:\n",
    "\n",
    "100 epochs and batch_size=len(train_labels)\n",
    "1 epoch and batch_size=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa053738-537d-4ef7-8e4e-37d990cfd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_full_batch = model.fit(train_images, train_labels, epochs=100, batch_size=len(train_labels), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46937dd4-6dff-4105-a1a4-949783aa8af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Batch Training (100 epochs)\n",
      "Training Loss: 0.2117, Training Accuracy: 0.9411\n",
      "Test Loss: 0.2105, Test Accuracy: 0.9398\n"
     ]
    }
   ],
   "source": [
    "train_loss_full, train_acc_full = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss_full, test_acc_full = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"100 epochs\")\n",
    "print(f\"Training Loss: {train_loss_full:.4f}, Training Accuracy: {train_acc_full:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_full:.4f}, Test Accuracy: {test_acc_full:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b285219-b727-41fd-b74d-bb114d71653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_sgd = model.fit(train_images, train_labels, epochs=1, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb14fda-5d00-4d43-84d8-6bf93df61573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 epoch, batch size 1)\n",
      "Training Loss: 0.1971, Training Accuracy: 0.9663\n",
      "Test Loss: 0.2047, Test Accuracy: 0.9641\n"
     ]
    }
   ],
   "source": [
    "train_loss_sgd, train_acc_sgd = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss_sgd, test_acc_sgd = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"\\n1 epoch, batch size 1)\")\n",
    "print(f\"Training Loss: {train_loss_sgd:.4f}, Training Accuracy: {train_acc_sgd:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_sgd:.4f}, Test Accuracy: {test_acc_sgd:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cd346-9c0f-4809-8a1d-9f815466ee0a",
   "metadata": {},
   "source": [
    "Task 9\n",
    "Check, whether further increasing the number of layers influences the accuracy of a deep learning model. Experiment with various numbers of parameters, batch sizes, and numbers of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738ba38-31a9-4dcb-ad83-6a5815dfad87",
   "metadata": {},
   "source": [
    "### 2 layers with 100 epoch and batch size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71a9298e-be7a-4bc7-9ad9-8f0cee578eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_two_layers = model.fit(train_images, train_labels, epochs=100, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b90333a-a35d-4491-92ee-e2506113578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 layers with 100 epoch and batch size 128\n",
      "Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Test Loss: 0.0832, Test Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "train_loss_two_layers, train_acc_two_layers = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss_two_layers, test_acc_two_layers = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"\\n2 layers with 100 epoch and batch size 128\")\n",
    "print(f\"Training Loss: {train_loss_two_layers:.4f}, Training Accuracy: {train_acc_two_layers:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_two_layers:.4f}, Test Accuracy: {test_acc_two_layers:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14000c40-2b9d-43ed-b241-9f29f4dea8c2",
   "metadata": {},
   "source": [
    "### 3 layers with 100 epoch and batch size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e75f6e85-8894-426b-a44b-459292d9a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(256, activation=\"softmax\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_three_layers = model.fit(train_images, train_labels, epochs=100, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f892f3c7-4f61-4b0b-bdaf-f595ae242222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 layers with 100 epoch and batch size 128\n",
      "Training Loss: 0.0182, Training Accuracy: 0.9988\n",
      "Test Loss: 0.2848, Test Accuracy: 0.9568\n"
     ]
    }
   ],
   "source": [
    "train_loss_three_layers, train_acc_three_layers = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss_three_layers, test_acc_three_layers = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"\\n3 layers with 100 epoch and batch size 128\")\n",
    "print(f\"Training Loss: {train_loss_three_layers:.4f}, Training Accuracy: {train_acc_three_layers:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_three_layers:.4f}, Test Accuracy: {test_acc_three_layers:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20466a-9163-41f2-881e-e8e7af89b889",
   "metadata": {},
   "source": [
    "### 5 layers with 100 epoch and batch size 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32c5ed24-2aaa-40a4-a5a8-177ca81e972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(256, activation=\"softmax\"),\n",
    "    layers.Dense(128, activation=\"softmax\"),\n",
    "    layers.Dense(64, activation=\"softmax\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_more_layers = model.fit(train_images, train_labels, epochs=100, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648feb13-bd2a-4d6a-9e13-d29d4bcbebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 layers with 100 epoch and batch size 128\n",
      "Training Loss: 2.3013, Training Accuracy: 0.1124\n",
      "Test Loss: 2.3012, Test Accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "train_loss_more_layers, train_acc_more_layers = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss_more_layers, test_acc_more_layers = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"\\n5 layers with 100 epoch and batch size 128\")\n",
    "print(f\"Training Loss: {train_loss_more_layers:.4f}, Training Accuracy: {train_acc_more_layers:.4f}\")\n",
    "print(f\"Test Loss: {test_loss_more_layers:.4f}, Test Accuracy: {test_acc_more_layers:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbdc50-cd23-4118-b858-f25bfaadc6a0",
   "metadata": {},
   "source": [
    "## 5 layers with 50 epoch and batch size 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df3116b3-39b4-4bd6-9efb-e70f96c0caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\", input_shape=(784,)),\n",
    "    layers.Dense(256, activation=\"softmax\"),\n",
    "    layers.Dense(128, activation=\"softmax\"),\n",
    "    layers.Dense(64, activation=\"softmax\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=50, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c063ecd4-203f-4da2-a717-a586acf6b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 layers with 50 epoch and batch size 64\n",
      "Training Loss: 2.3012, Training Accuracy: 0.1124\n",
      "Test Loss: 2.3010, Test Accuracy: 0.1135\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=0)\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "\n",
    "print(\"\\n5 layers with 50 epoch and batch size 64\")\n",
    "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
